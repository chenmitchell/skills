"""
Task Workflow V3 - Persistence Module
ä»»åŠ¡æŒä¹…åŒ–æ¨¡å— - æ”¯æŒæ–‡ä»¶è½ç›˜å’Œè¿›åº¦è¿½è¸ª
"""

import os
import yaml
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field, asdict
from pathlib import Path
from enum import Enum


class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    MIGRATED = "migrated"


@dataclass
class TaskRecord:
    """ä»»åŠ¡è®°å½• - å¯åºåˆ—åŒ–çš„ä»»åŠ¡æ•°æ®"""
    id: str
    name: str
    description: str = ""
    depends_on: List[str] = field(default_factory=list)
    estimated_time: str = "medium"
    tool_calls_estimate: int = 5
    decision_points: int = 0
    complexity_score: float = 0.0
    status: str = "pending"
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    started_at: Optional[str] = None
    completed_at: Optional[str] = None
    batch_number: int = 0
    notes: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TaskRecord':
        return cls(**data)


@dataclass
class ProgressSnapshot:
    """è¿›åº¦å¿«ç…§"""
    timestamp: str
    total_tasks: int
    completed_tasks: int
    running_tasks: int
    pending_tasks: int
    completion_rate: float
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class TaskPersistenceManager:
    """ä»»åŠ¡æŒä¹…åŒ–ç®¡ç†å™¨"""
    
    DEFAULT_BACKLOG_DIR = "/root/.openclaw/workspace/task_backlog"
    FILENAME_FORMAT = "task-workflow-progress-{date}.md"
    
    def __init__(self, backlog_dir: Optional[str] = None):
        self.backlog_dir = Path(backlog_dir or self.DEFAULT_BACKLOG_DIR)
        self.backlog_dir.mkdir(parents=True, exist_ok=True)
        self._current_date = datetime.now().strftime("%Y-%m-%d")
        self._current_file: Optional[Path] = None
        self._tasks: Dict[str, TaskRecord] = {}
    
    def _get_filename(self, date_str: Optional[str] = None) -> str:
        """ç”Ÿæˆæ–‡ä»¶å"""
        date = date_str or datetime.now().strftime("%Y-%m-%d")
        return self.FILENAME_FORMAT.format(date=date)
    
    def _get_filepath(self, date_str: Optional[str] = None) -> Path:
        """è·å–å®Œæ•´æ–‡ä»¶è·¯å¾„"""
        return self.backlog_dir / self._get_filename(date_str)
    
    def initialize_daily_file(self, date_str: Optional[str] = None) -> Path:
        """åˆå§‹åŒ–æ¯æ—¥ä»»åŠ¡æ–‡ä»¶"""
        filepath = self._get_filepath(date_str)
        
        if not filepath.exists():
            # æ£€æŸ¥å‰ä¸€å¤©æ˜¯å¦æœ‰æœªå®Œæˆä»»åŠ¡éœ€è¦è¿ç§»
            yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
            migrated_tasks = self._migrate_incomplete_tasks(yesterday)
            
            # åˆ›å»ºæ–°æ–‡ä»¶
            self._create_markdown_file(filepath, migrated_tasks)
        else:
            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œè§£æç°æœ‰ä»»åŠ¡
            content = filepath.read_text(encoding='utf-8')
            existing_tasks = self._parse_tasks_from_markdown(content)
            for task in existing_tasks:
                self._tasks[task.id] = task
        
        self._current_file = filepath
        return filepath
    
    def _migrate_incomplete_tasks(self, from_date: str) -> List[TaskRecord]:
        """è¿ç§»å‰ä¸€å¤©æœªå®Œæˆçš„ä»»åŠ¡"""
        old_file = self._get_filepath(from_date)
        migrated = []
        
        if old_file.exists():
            content = old_file.read_text(encoding='utf-8')
            tasks = self._parse_tasks_from_markdown(content)
            
            for task in tasks:
                if task.status not in ["completed", "migrated"]:
                    task.status = "migrated"
                    task.notes += f"\n[Auto-migrated from {from_date}]"
                    migrated.append(task)
        
        return migrated
    
    def _create_markdown_file(self, filepath: Path, migrated_tasks: List[TaskRecord] = None):
        """åˆ›å»º Markdown ä»»åŠ¡æ–‡ä»¶"""
        date_str = filepath.stem.split("-")[-3:]
        date = "-".join(date_str)
        
        content = f"""# Task Workflow Progress - {date}

**Generated**: {datetime.now().isoformat()}  
**Status**: ğŸŸ¢ Active  
**Auto-archive**: CST 00:00 next day

---

## ğŸ“‹ Task List

| ID | Task | Complexity | Dependencies | Status | Batch |
|----|------|-----------|--------------|--------|-------|
"""
        
        # æ·»åŠ è¿ç§»çš„ä»»åŠ¡
        if migrated_tasks:
            content += "\n### ğŸ”„ Migrated from Previous Day\n\n"
            for task in migrated_tasks:
                task.status = "pending"  # é‡ç½®ä¸ºå¾…æ‰§è¡Œ
                deps = ", ".join(task.depends_on) if task.depends_on else "-"
                content += f"| {task.id} | {task.name} | {task.complexity_score:.1f} | {deps} | â³ Pending | - |\n"
                self._tasks[task.id] = task
        
        content += f"""

## ğŸ“Š Progress Tracking

| Timestamp | Event | Details |
|-----------|-------|---------|
| {datetime.now().strftime("%H:%M")} | File Created | Daily workflow initialized |

---

## ğŸ“ˆ Statistics

- **Total Tasks**: {len(migrated_tasks) if migrated_tasks else 0}
- **Completed**: 0
- **Pending**: {len(migrated_tasks) if migrated_tasks else 0}
- **Completion Rate**: 0%

---

## âœ… Completion Checklist

- [ ] All tasks completed
- [ ] Progress reviewed
- [ ] File archived

---

*Auto-generated by Task Workflow V3*
"""
        
        filepath.write_text(content, encoding='utf-8')
    
    def add_task(self, task: TaskRecord):
        """æ·»åŠ ä»»åŠ¡åˆ°å½“å‰æ–‡ä»¶"""
        self._tasks[task.id] = task
        self._update_markdown()
    
    def update_task_status(self, task_id: str, status: TaskStatus, notes: str = ""):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        if task_id in self._tasks:
            task = self._tasks[task_id]
            task.status = status.value
            
            if status == TaskStatus.RUNNING and not task.started_at:
                task.started_at = datetime.now().isoformat()
            elif status in [TaskStatus.COMPLETED, TaskStatus.FAILED]:
                task.completed_at = datetime.now().isoformat()
            
            if notes:
                task.notes += f"\n{notes}"
            
            self._update_markdown()
    
    def _update_markdown(self):
        """æ›´æ–° Markdown æ–‡ä»¶å†…å®¹"""
        if not self._current_file or not self._current_file.exists():
            return
        
        # æ„å»ºä»»åŠ¡è¡¨æ ¼
        task_rows = []
        status_icons = {
            "pending": "â³",
            "running": "ğŸ”„",
            "completed": "âœ…",
            "failed": "âŒ",
            "migrated": "ğŸ“¦"
        }
        
        for task in self._tasks.values():
            icon = status_icons.get(task.status, "â³")
            deps = ", ".join(task.depends_on) if task.depends_on else "-"
            batch = str(task.batch_number) if task.batch_number > 0 else "-"
            task_rows.append(
                f"| {task.id} | {task.name} | {task.complexity_score:.1f} | {deps} | {icon} {task.status.title()} | {batch} |"
            )
        
        # ç»Ÿè®¡ä¿¡æ¯
        total = len(self._tasks)
        completed = sum(1 for t in self._tasks.values() if t.status == "completed")
        pending = sum(1 for t in self._tasks.values() if t.status == "pending")
        running = sum(1 for t in self._tasks.values() if t.status == "running")
        rate = (completed / total * 100) if total > 0 else 0
        
        # è¯»å–å½“å‰æ–‡ä»¶
        content = self._current_file.read_text(encoding='utf-8')
        
        # è§£æå¹¶é‡å»ºæ•´ä¸ªæ–‡ä»¶
        sections = self._parse_sections(content)
        
        # é‡å»ºä»»åŠ¡åˆ—è¡¨éƒ¨åˆ†
        task_section = ["## ğŸ“‹ Task List", ""]
        task_section.append("| ID | Task | Complexity | Dependencies | Status | Batch |")
        task_section.append("|----|------|-----------|--------------|--------|-------|")
        task_section.extend(task_rows)
        
        # é‡å»ºæ–‡ä»¶å†…å®¹
        new_content = sections['header'] + '\n\n'
        new_content += '\n'.join(task_section) + '\n\n'
        new_content += sections['progress'] + '\n\n'
        new_content += self._build_statistics_section(total, completed, pending, running, rate) + '\n\n'
        new_content += sections['footer']
        
        self._current_file.write_text(new_content, encoding='utf-8')
    
    def _parse_sections(self, content: str) -> dict:
        """è§£æ markdown æ–‡ä»¶ä¸ºå„ä¸ªéƒ¨åˆ†"""
        sections = {
            'header': '',
            'progress': '',
            'footer': ''
        }
        
        lines = content.split('\n')
        current_section = 'header'
        section_lines = []
        
        for line in lines:
            if line.startswith("## ğŸ“‹ Task List"):
                sections['header'] = '\n'.join(section_lines).rstrip()
                current_section = 'tasks'
                section_lines = []
            elif line.startswith("## ğŸ“Š Progress Tracking") and current_section == 'tasks':
                current_section = 'progress'
                section_lines = [line]
            elif line.startswith("## ğŸ“ˆ Statistics") and current_section == 'progress':
                sections['progress'] = '\n'.join(section_lines).rstrip()
                current_section = 'stats'
                section_lines = [line]
            elif line.startswith("## âœ… Completion") and current_section in ['stats', 'progress']:
                if current_section == 'stats':
                    section_lines = []
                current_section = 'footer'
                section_lines = [line]
            else:
                section_lines.append(line)
        
        if current_section == 'progress':
            sections['progress'] = '\n'.join(section_lines).rstrip()
        elif current_section == 'footer':
            sections['footer'] = '\n'.join(section_lines).rstrip()
        
        # ç¡®ä¿ progress éƒ¨åˆ†æœ‰åŸºæœ¬ç»“æ„
        if not sections['progress']:
            sections['progress'] = """## ğŸ“Š Progress Tracking

| Timestamp | Event | Details |
|-----------|-------|---------|"""
        
        # ç¡®ä¿ footer å­˜åœ¨
        if not sections['footer']:
            sections['footer'] = """## âœ… Completion Checklist

- [ ] All tasks completed
- [ ] Progress reviewed
- [ ] File archived

---

*Auto-generated by Task Workflow V3*"""
        
        return sections
    
    def _build_statistics_section(self, total: int, completed: int, pending: int, running: int, rate: float) -> str:
        """æ„å»ºç»Ÿè®¡éƒ¨åˆ†"""
        return f"""## ğŸ“ˆ Statistics

- **Total Tasks**: {total}
- **Completed**: {completed}
- **Running**: {running}
- **Pending**: {pending}
- **Completion Rate**: {rate:.1f}%"""
    
    def _update_statistics_section(self, content: str, total: int, completed: int, 
                                    pending: int, running: int, rate: float) -> str:
        """æ›´æ–°ç»Ÿè®¡éƒ¨åˆ†"""
        lines = content.split('\n')
        new_lines = []
        in_stats = False
        
        for line in lines:
            if "## ğŸ“ˆ Statistics" in line:
                in_stats = True
                new_lines.append(line)
                new_lines.append(f"\n- **Total Tasks**: {total}")
                new_lines.append(f"- **Completed**: {completed}")
                new_lines.append(f"- **Running**: {running}")
                new_lines.append(f"- **Pending**: {pending}")
                new_lines.append(f"- **Completion Rate**: {rate:.1f}%")
                continue
            
            if in_stats and line.startswith("- **"):
                continue  # è·³è¿‡æ—§ç»Ÿè®¡
            if in_stats and line.strip().startswith("*Auto-generated"):
                in_stats = False
            
            if not in_stats or line.strip().startswith("*Auto-generated"):
                new_lines.append(line)
        
        return '\n'.join(new_lines)
    
    def _parse_tasks_from_markdown(self, content: str) -> List[TaskRecord]:
        """ä» Markdown è§£æä»»åŠ¡"""
        tasks = []
        lines = content.split('\n')
        
        for line in lines:
            if line.startswith('| ') and not line.startswith('|----') and not line.startswith('| ID'):
                parts = [p.strip() for p in line.split('|')[1:-1]]
                if len(parts) >= 5:
                    task = TaskRecord(
                        id=parts[0],
                        name=parts[1],
                        complexity_score=float(parts[2]) if parts[2] != '-' else 0.0,
                        depends_on=parts[3].split(', ') if parts[3] != '-' else [],
                        status=parts[4].split()[-1].lower() if ' ' in parts[4] else parts[4].lower()
                    )
                    tasks.append(task)
        
        return tasks
    
    def log_progress(self, event: str, details: str = ""):
        """è®°å½•è¿›åº¦äº‹ä»¶"""
        if not self._current_file or not self._current_file.exists():
            return
        
        timestamp = datetime.now().strftime("%H:%M")
        new_line = f"| {timestamp} | {event} | {details} |"
        
        content = self._current_file.read_text(encoding='utf-8')
        
        # æ‰¾åˆ° Progress Tracking è¡¨æ ¼å¹¶æ’å…¥æ–°è¡Œ
        lines = content.split('\n')
        new_lines = []
        in_progress_table = False
        table_header_found = False
        
        for i, line in enumerate(lines):
            if "## ğŸ“Š Progress Tracking" in line:
                in_progress_table = True
                new_lines.append(line)
                continue
            
            if in_progress_table and line.startswith("|----"):
                table_header_found = True
                new_lines.append(line)
                continue
            
            if table_header_found and line.startswith("|") and not line.startswith("|----"):
                new_lines.append(line)
                continue
            
            if table_header_found and line.strip() == "" and not line.startswith("|"):
                # è¡¨æ ¼ç»“æŸï¼Œæ’å…¥æ–°è¡Œ
                new_lines.append(new_line)
                new_lines.append("")
                table_header_found = False
                in_progress_table = False
            
            new_lines.append(line)
        
        content = '\n'.join(new_lines)
        self._current_file.write_text(content, encoding='utf-8')
    
    def get_current_tasks(self) -> List[TaskRecord]:
        """è·å–å½“å‰æ‰€æœ‰ä»»åŠ¡"""
        return list(self._tasks.values())
    
    def archive_completed(self):
        """å½’æ¡£å·²å®Œæˆçš„ä»»åŠ¡"""
        # æ ‡è®°å®ŒæˆçŠ¶æ€
        if self._current_file and self._current_file.exists():
            content = self._current_file.read_text(encoding='utf-8')
            content = content.replace("**Status**: ğŸŸ¢ Active", "**Status**: ğŸ”µ Archived")
            self._current_file.write_text(content, encoding='utf-8')


class CronConfigManager:
    """Cron é…ç½®ç®¡ç†å™¨"""
    
    CONFIG_FILE = "/root/.openclaw/workspace/skills/task-workflow-v3/config/cron.yaml"
    
    def __init__(self):
        self.config_path = Path(self.CONFIG_FILE)
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
    
    def generate_default_config(self) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤ cron é…ç½®"""
        return {
            "cron_jobs": [
                {
                    "name": "task-workflow-daily-init",
                    "schedule": "0 0 * * *",  # CST 0:00
                    "command": "python -m task_workflow_v3.cli init-daily",
                    "description": "Initialize daily task workflow file",
                    "enabled": True
                },
                {
                    "name": "task-workflow-cleanup",
                    "schedule": "0 1 * * *",
                    "command": "python -m task_workflow_v3.cli cleanup-old-files --days 30",
                    "description": "Clean up old task files older than 30 days",
                    "enabled": True
                }
            ],
            "settings": {
                "timezone": "Asia/Shanghai",
                "auto_migrate": True,
                "retention_days": 30
            }
        }
    
    def save_config(self, config: Optional[Dict[str, Any]] = None):
        """ä¿å­˜é…ç½®åˆ° YAML æ–‡ä»¶"""
        config = config or self.generate_default_config()
        with open(self.config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    def load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return self.generate_default_config()
    
    def get_openclaw_cron_api_payload(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆ OpenClaw Cron API æ ¼å¼çš„é…ç½®"""
        config = self.load_config()
        jobs = []
        
        for job in config.get("cron_jobs", []):
            if job.get("enabled", False):
                jobs.append({
                    "name": job["name"],
                    "schedule": job["schedule"],
                    "command": job["command"],
                    "enabled": True
                })
        
        return jobs


# ä¾¿æ·å‡½æ•°
def get_today_file_path() -> Path:
    """è·å–ä»Šæ—¥ä»»åŠ¡æ–‡ä»¶è·¯å¾„"""
    date_str = datetime.now().strftime("%Y-%m-%d")
    return Path(TaskPersistenceManager.DEFAULT_BACKLOG_DIR) / f"task-workflow-progress-{date_str}.md"


def ensure_daily_file_exists() -> Path:
    """ç¡®ä¿ä»Šæ—¥æ–‡ä»¶å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º"""
    manager = TaskPersistenceManager()
    return manager.initialize_daily_file()
