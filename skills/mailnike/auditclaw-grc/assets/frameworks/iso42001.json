{
  "$schema": "framework-definition-v1",
  "id": "iso42001",
  "name": "ISO/IEC 42001:2023",
  "version": "2023",
  "description": "Artificial Intelligence Management System (AIMS) — requirements for establishing, implementing, maintaining and continually improving an AI management system within the context of an organization",
  "domains": [
    {
      "id": "4",
      "name": "Context of the Organization",
      "description": "Understanding the organization, stakeholder needs, AIMS scope, and the AI management system itself",
      "controls": [
        {
          "id": "4.1",
          "title": "Understanding the organization and its context",
          "description": "The organization shall determine external and internal issues relevant to its purpose that affect its ability to achieve the intended outcomes of its AI management system, including AI-specific considerations such as regulatory landscape, societal expectations, and the state of AI technology.",
          "category": "Context",
          "priority": 3,
          "typical_evidence": ["AI context analysis document", "PESTLE analysis covering AI factors", "AI regulatory landscape assessment", "Internal AI capability assessment"],
          "mappings": {"iso27001": ["4.1"], "soc2": ["CC1.1"], "nist-csf": ["ID.BE-1", "ID.BE-2"]}
        },
        {
          "id": "4.2",
          "title": "Understanding the needs and expectations of interested parties",
          "description": "The organization shall determine the interested parties relevant to the AI management system, their requirements regarding responsible AI, and which of these requirements will be addressed through the AIMS.",
          "category": "Context",
          "priority": 3,
          "typical_evidence": ["Stakeholder register for AI systems", "Interested party requirements matrix", "AI ethics expectations register", "Regulatory requirements inventory"],
          "mappings": {"iso27001": ["4.2"], "soc2": ["CC1.1", "CC2.2"], "nist-csf": ["ID.GV-2"]}
        },
        {
          "id": "4.3",
          "title": "Determining the scope of the AI management system",
          "description": "The organization shall determine the boundaries and applicability of the AI management system to establish its scope, considering AI systems in development, deployment, and use across the organization.",
          "category": "Context",
          "priority": 3,
          "typical_evidence": ["AIMS scope statement", "AI system inventory", "Scope boundary documentation", "In-scope AI application register"],
          "mappings": {"iso27001": ["4.3"], "soc2": ["CC1.1"], "nist-csf": ["ID.AM-1", "ID.AM-2"]}
        },
        {
          "id": "4.4",
          "title": "AI management system",
          "description": "The organization shall establish, implement, maintain and continually improve an AI management system, including the processes needed and their interactions, in accordance with the requirements of this document.",
          "category": "Context",
          "priority": 4,
          "typical_evidence": ["AIMS documentation", "Process interaction diagrams", "AI governance framework document", "AIMS process map"],
          "mappings": {"iso27001": ["4.4"], "soc2": ["CC1.1", "CC5.1"], "nist-csf": ["ID.GV-1"]}
        }
      ]
    },
    {
      "id": "5",
      "name": "Leadership",
      "description": "Top management commitment, AI policy, and organizational roles, responsibilities, and authorities",
      "controls": [
        {
          "id": "5.1",
          "title": "Leadership and commitment",
          "description": "Top management shall demonstrate leadership and commitment with respect to the AI management system by ensuring responsible AI policy and objectives are established, resources are available, and the importance of effective AI governance is communicated.",
          "category": "Leadership",
          "priority": 4,
          "typical_evidence": ["Board resolution on AI governance", "Management review meeting minutes", "AI budget allocation records", "Executive AI responsibility assignment"],
          "mappings": {"iso27001": ["5.1"], "soc2": ["CC1.1", "CC1.2"], "nist-csf": ["ID.GV-1"]}
        },
        {
          "id": "5.2",
          "title": "AI policy",
          "description": "Top management shall establish an AI policy that is appropriate to the purpose of the organization, includes commitment to responsible AI principles, provides a framework for setting AI objectives, and commits to continual improvement of the AIMS.",
          "category": "Leadership",
          "priority": 4,
          "typical_evidence": ["AI policy document", "Responsible AI principles statement", "AI ethics charter", "Policy communication records", "Policy approval and sign-off"],
          "mappings": {"iso27001": ["5.2", "A5.1.1"], "soc2": ["CC1.1", "CC5.3"], "nist-csf": ["ID.GV-1", "ID.GV-2"]}
        },
        {
          "id": "5.3",
          "title": "Organizational roles, responsibilities and authorities",
          "description": "Top management shall ensure that the responsibilities and authorities for roles relevant to the AI management system are assigned and communicated, including roles for AI ethics oversight, AI risk management, and AI system lifecycle governance.",
          "category": "Leadership",
          "priority": 4,
          "typical_evidence": ["AI governance RACI matrix", "AI ethics board charter", "AI role descriptions", "AI system owner assignments", "Organizational AI responsibility chart"],
          "mappings": {"iso27001": ["5.3", "A6.1.1"], "soc2": ["CC1.3", "CC5.1"], "nist-csf": ["ID.GV-1", "ID.AM-6"]}
        },
        {
          "id": "5.4",
          "title": "Responsible AI commitment",
          "description": "Top management shall establish and communicate a commitment to responsible AI that addresses fairness, transparency, accountability, safety, and human oversight of AI systems throughout their lifecycle.",
          "category": "Leadership",
          "priority": 5,
          "typical_evidence": ["Responsible AI commitment statement", "AI ethics principles documentation", "Public AI transparency report", "Stakeholder communication records on responsible AI"],
          "mappings": {"iso27001": ["5.1"], "soc2": ["CC1.1", "CC1.4"], "nist-csf": ["ID.GV-1", "ID.GV-4"]}
        }
      ]
    },
    {
      "id": "6",
      "name": "Planning",
      "description": "Actions to address risks and opportunities, AI objectives, and planning of changes related to AI systems",
      "controls": [
        {
          "id": "6.1",
          "title": "Actions to address risks and opportunities",
          "description": "When planning for the AI management system, the organization shall consider the issues and requirements from clauses 4.1 and 4.2, and determine the risks and opportunities, including AI-specific risks such as bias, safety, and societal impact.",
          "category": "Planning",
          "priority": 4,
          "typical_evidence": ["AI risk register", "AI opportunity assessment", "Risk treatment plan for AI systems", "AI risk-opportunity matrix"],
          "mappings": {"iso27001": ["6.1"], "soc2": ["CC3.1", "CC3.2"], "nist-csf": ["ID.RA-1", "ID.RA-3"]}
        },
        {
          "id": "6.1.2",
          "title": "AI risk assessment",
          "description": "The organization shall define and apply an AI risk assessment process that identifies risks associated with AI systems including algorithmic bias, data quality issues, safety hazards, privacy concerns, and societal harms.",
          "category": "Planning",
          "priority": 5,
          "typical_evidence": ["AI risk assessment methodology", "AI risk assessment reports", "Bias risk evaluation records", "AI safety risk analysis", "Societal impact assessment"],
          "mappings": {"iso27001": ["6.1.2", "A8.2.1"], "soc2": ["CC3.2", "CC3.4"], "nist-csf": ["ID.RA-1", "ID.RA-2", "ID.RA-3"]}
        },
        {
          "id": "6.1.3",
          "title": "AI risk treatment",
          "description": "The organization shall define and apply an AI risk treatment process to select appropriate options for treating AI-specific risks and produce a statement of applicability for the controls in Annex A.",
          "category": "Planning",
          "priority": 5,
          "typical_evidence": ["AI risk treatment plan", "Statement of applicability (SoA)", "Residual risk acceptance records", "AI risk mitigation action log"],
          "mappings": {"iso27001": ["6.1.3"], "soc2": ["CC3.2", "CC5.2"], "nist-csf": ["ID.RA-6", "PR.IP-12"]}
        },
        {
          "id": "6.2",
          "title": "AI objectives and planning to achieve them",
          "description": "The organization shall establish AI objectives at relevant functions, levels and processes, ensuring they are consistent with the AI policy, measurable, communicated, updated as appropriate, and include responsible AI metrics.",
          "category": "Planning",
          "priority": 3,
          "typical_evidence": ["AI objectives register", "AI KPI dashboard", "Responsible AI metrics framework", "AI objective achievement plans"],
          "mappings": {"iso27001": ["6.2"], "soc2": ["CC5.2", "CC5.3"], "nist-csf": ["ID.GV-4"]}
        },
        {
          "id": "6.3",
          "title": "Planning of changes",
          "description": "When the organization determines the need for changes to the AI management system, the changes shall be carried out in a planned manner, considering the purpose and consequences of changes to AI systems and governance processes.",
          "category": "Planning",
          "priority": 3,
          "typical_evidence": ["AI change management process", "Change impact assessment records", "AIMS change request log", "AI system change approval records"],
          "mappings": {"iso27001": ["6.3"], "soc2": ["CC8.1"], "nist-csf": ["PR.IP-3"]}
        }
      ]
    },
    {
      "id": "7",
      "name": "Support",
      "description": "Resources, competence, awareness, communication, and documented information for the AI management system",
      "controls": [
        {
          "id": "7.1",
          "title": "Resources",
          "description": "The organization shall determine and provide the resources needed for the establishment, implementation, maintenance and continual improvement of the AI management system, including AI-specific technical infrastructure, tools, and computing resources.",
          "category": "Support",
          "priority": 3,
          "typical_evidence": ["AI resource allocation plan", "AI infrastructure inventory", "AI computing budget", "AI tooling inventory", "Resource capacity assessment"],
          "mappings": {"iso27001": ["7.1"], "soc2": ["CC1.4"], "nist-csf": ["ID.AM-1", "ID.AM-2"]}
        },
        {
          "id": "7.2",
          "title": "Competence",
          "description": "The organization shall determine the necessary competence of persons doing work that affects AI system performance and responsible AI, ensure these persons are competent on the basis of appropriate education, training, or experience, and maintain records of competence.",
          "category": "Support",
          "priority": 4,
          "typical_evidence": ["AI competence framework", "AI training program records", "AI certification records", "AI skills matrix", "AI ethics training completion records"],
          "mappings": {"iso27001": ["7.2", "A7.2.2"], "soc2": ["CC1.4"], "nist-csf": ["PR.AT-1", "PR.AT-2"]}
        },
        {
          "id": "7.3",
          "title": "Awareness",
          "description": "Persons doing work under the organization's control shall be aware of the AI policy, their contribution to the effectiveness of the AIMS, the implications of not conforming with AIMS requirements, and responsible AI principles.",
          "category": "Support",
          "priority": 3,
          "typical_evidence": ["AI awareness training materials", "AI policy acknowledgment records", "Responsible AI awareness campaign records", "AI governance communication logs"],
          "mappings": {"iso27001": ["7.3"], "soc2": ["CC1.4", "CC2.2"], "nist-csf": ["PR.AT-1"]}
        },
        {
          "id": "7.4",
          "title": "Communication",
          "description": "The organization shall determine the need for internal and external communications relevant to the AI management system, including what, when, with whom, and how to communicate about AI governance, incidents, and responsible AI practices.",
          "category": "Support",
          "priority": 3,
          "typical_evidence": ["AI communication plan", "AI incident communication procedures", "Stakeholder AI communication log", "AI transparency reporting schedule"],
          "mappings": {"iso27001": ["7.4"], "soc2": ["CC2.1", "CC2.2", "CC2.3"], "nist-csf": ["RS.CO-1", "RS.CO-2"]}
        },
        {
          "id": "7.5",
          "title": "Documented information",
          "description": "The AI management system shall include documented information required by this document and determined by the organization as necessary for the effectiveness of the AIMS, including AI model documentation, data provenance records, and decision logs.",
          "category": "Support",
          "priority": 3,
          "typical_evidence": ["AIMS document control procedure", "AI model documentation standards", "Document retention schedule for AI artifacts", "Data provenance record templates", "AI system documentation repository"],
          "mappings": {"iso27001": ["7.5", "A12.1.1"], "soc2": ["CC5.3"], "nist-csf": ["PR.IP-1"]}
        }
      ]
    },
    {
      "id": "8",
      "name": "Operation",
      "description": "Operational planning, AI impact assessment, AI system lifecycle, data management for AI, and third-party AI considerations",
      "controls": [
        {
          "id": "8.1",
          "title": "Operational planning and control",
          "description": "The organization shall plan, implement and control the processes needed to meet AI management system requirements and to implement the actions determined in clause 6, including establishing criteria for AI processes and implementing control of AI processes in accordance with the criteria.",
          "category": "Operation",
          "priority": 4,
          "typical_evidence": ["AI operational procedures manual", "AI system deployment checklists", "AI process control documentation", "Operational AI risk controls register"],
          "mappings": {"iso27001": ["8.1"], "soc2": ["CC7.1", "CC7.2"], "nist-csf": ["PR.IP-1", "DE.CM-1"]}
        },
        {
          "id": "8.2",
          "title": "AI impact assessment",
          "description": "The organization shall conduct AI impact assessments for AI systems to evaluate potential impacts on individuals, groups, and society, including impacts on human rights, fairness, safety, privacy, and the environment, before deployment and at defined intervals.",
          "category": "Operation",
          "priority": 5,
          "typical_evidence": ["AI impact assessment methodology", "Completed AI impact assessment reports", "Human rights impact analysis", "Environmental impact assessment for AI", "Fairness impact evaluation", "Stakeholder consultation records"],
          "mappings": {"iso27001": ["A14.1.1"], "soc2": ["CC3.2", "CC9.2"], "nist-csf": ["ID.RA-1", "ID.RA-2"]}
        },
        {
          "id": "8.3",
          "title": "AI system lifecycle management",
          "description": "The organization shall establish processes for managing the AI system lifecycle, including design, development, testing, deployment, monitoring, and decommissioning of AI systems, ensuring responsible AI practices at each stage.",
          "category": "Operation",
          "priority": 4,
          "typical_evidence": ["AI system lifecycle policy", "AI development methodology documentation", "AI testing and validation reports", "AI deployment approval records", "AI model decommissioning procedure", "AI system change history log"],
          "mappings": {"iso27001": ["A14.2.1", "A14.2.2"], "soc2": ["CC7.1", "CC8.1"], "nist-csf": ["PR.IP-2", "PR.IP-3"]}
        },
        {
          "id": "8.4",
          "title": "Data management for AI systems",
          "description": "The organization shall establish processes for managing data used in AI systems, addressing data quality, data provenance, data bias assessment, data representativeness, and data governance throughout the AI lifecycle.",
          "category": "Operation",
          "priority": 5,
          "typical_evidence": ["AI data governance policy", "Data quality assessment reports", "Data provenance tracking records", "Training data bias analysis reports", "Data representativeness evaluation", "Data lineage documentation"],
          "mappings": {"iso27001": ["A8.2.1", "A8.2.3"], "soc2": ["CC6.1", "PI1.2"], "nist-csf": ["PR.DS-1", "PR.DS-6"]}
        },
        {
          "id": "8.5",
          "title": "Third-party and supply chain considerations for AI",
          "description": "The organization shall address AI-related risks arising from third-party products, services, and components, including pre-trained models, third-party datasets, AI-as-a-Service providers, and open-source AI components.",
          "category": "Operation",
          "priority": 4,
          "typical_evidence": ["AI supply chain risk assessment", "Third-party AI vendor evaluation records", "AI component provenance register", "Pre-trained model assessment reports", "AI vendor contractual requirements"],
          "mappings": {"iso27001": ["A15.1.1", "A15.2.1"], "soc2": ["CC9.2"], "nist-csf": ["ID.SC-1", "ID.SC-2", "ID.SC-3"]}
        },
        {
          "id": "8.6",
          "title": "AI system testing and validation",
          "description": "The organization shall establish testing and validation processes for AI systems to ensure they perform as intended, meet quality requirements, and do not produce harmful or unintended outcomes prior to deployment.",
          "category": "Operation",
          "priority": 4,
          "typical_evidence": ["AI testing strategy document", "Model validation reports", "AI acceptance test results", "Performance benchmark records", "Adversarial testing results", "Edge case test documentation"],
          "mappings": {"iso27001": ["A14.2.8", "A14.2.9"], "soc2": ["CC7.1", "CC8.1"], "nist-csf": ["PR.IP-2", "DE.DP-3"]}
        }
      ]
    },
    {
      "id": "9",
      "name": "Performance Evaluation",
      "description": "Monitoring, measurement, analysis, evaluation, internal audit, and management review of the AIMS",
      "controls": [
        {
          "id": "9.1",
          "title": "Monitoring, measurement, analysis and evaluation",
          "description": "The organization shall determine what needs to be monitored and measured for AI systems, including AI performance metrics, fairness indicators, drift detection, and responsible AI KPIs, and evaluate the effectiveness of the AIMS.",
          "category": "Performance Evaluation",
          "priority": 4,
          "typical_evidence": ["AI performance monitoring dashboard", "AI fairness metrics reports", "Model drift detection reports", "AIMS effectiveness evaluation", "AI KPI tracking records"],
          "mappings": {"iso27001": ["9.1"], "soc2": ["CC4.1", "CC4.2"], "nist-csf": ["DE.AE-1", "DE.CM-1"]}
        },
        {
          "id": "9.2",
          "title": "Internal audit",
          "description": "The organization shall conduct internal audits at planned intervals to provide information on whether the AI management system conforms to its own requirements and the requirements of this document, and is effectively implemented and maintained.",
          "category": "Performance Evaluation",
          "priority": 4,
          "typical_evidence": ["AIMS internal audit program", "AI audit checklists", "Internal audit reports for AIMS", "Audit findings and corrective actions", "Auditor competence records for AI auditing"],
          "mappings": {"iso27001": ["9.2"], "soc2": ["CC4.1", "CC4.2"], "nist-csf": ["DE.DP-1", "DE.DP-5"]}
        },
        {
          "id": "9.3",
          "title": "Management review",
          "description": "Top management shall review the organization's AI management system at planned intervals to ensure its continuing suitability, adequacy and effectiveness, including review of AI incidents, responsible AI metrics, and emerging AI risks.",
          "category": "Performance Evaluation",
          "priority": 3,
          "typical_evidence": ["AIMS management review meeting minutes", "AI incident summary reports", "Responsible AI metrics dashboard for management", "AIMS improvement action items", "Management review schedule"],
          "mappings": {"iso27001": ["9.3"], "soc2": ["CC4.2", "CC5.3"], "nist-csf": ["ID.GV-4"]}
        },
        {
          "id": "9.4",
          "title": "AI system performance monitoring",
          "description": "The organization shall establish ongoing monitoring of deployed AI systems to detect performance degradation, data drift, concept drift, bias emergence, and anomalous behavior, and shall define thresholds and response procedures.",
          "category": "Performance Evaluation",
          "priority": 5,
          "typical_evidence": ["AI monitoring architecture document", "Model performance baseline records", "Drift detection alert configuration", "Bias monitoring dashboards", "Anomaly detection procedure", "Monitoring threshold documentation"],
          "mappings": {"iso27001": ["A12.4.1"], "soc2": ["CC7.2", "CC7.3"], "nist-csf": ["DE.CM-1", "DE.CM-7", "DE.AE-1"]}
        }
      ]
    },
    {
      "id": "10",
      "name": "Improvement",
      "description": "Nonconformity, corrective action, and continual improvement of the AI management system",
      "controls": [
        {
          "id": "10.1",
          "title": "Nonconformity and corrective action",
          "description": "When a nonconformity occurs, including AI incidents, bias events, or system failures, the organization shall react to the nonconformity, evaluate the need for action to eliminate the causes, implement any action needed, and review the effectiveness of corrective actions.",
          "category": "Improvement",
          "priority": 4,
          "typical_evidence": ["AI incident register", "Nonconformity reports for AI systems", "Root cause analysis records", "Corrective action plans", "Corrective action effectiveness reviews", "AI incident post-mortem reports"],
          "mappings": {"iso27001": ["10.1", "A16.1.5"], "soc2": ["CC4.2", "CC7.3"], "nist-csf": ["RS.AN-1", "RS.MI-1", "RS.MI-2"]}
        },
        {
          "id": "10.2",
          "title": "Continual improvement",
          "description": "The organization shall continually improve the suitability, adequacy and effectiveness of the AI management system, incorporating lessons learned from AI incidents, advances in responsible AI practices, and evolving regulatory requirements.",
          "category": "Improvement",
          "priority": 3,
          "typical_evidence": ["AIMS improvement program", "Lessons learned register for AI", "AI maturity assessment records", "Improvement initiative tracking", "Responsible AI practice evolution log"],
          "mappings": {"iso27001": ["10.2"], "soc2": ["CC4.2", "CC5.3"], "nist-csf": ["ID.GV-4", "PR.IP-7"]}
        },
        {
          "id": "10.3",
          "title": "AI-specific corrective and preventive measures",
          "description": "The organization shall implement AI-specific corrective and preventive measures to address systemic issues discovered through monitoring, auditing, or incident response, including model retraining, data remediation, and algorithm adjustments.",
          "category": "Improvement",
          "priority": 4,
          "typical_evidence": ["Model retraining decision records", "Data remediation plans", "Algorithm adjustment logs", "Preventive action register for AI systems", "Systematic issue analysis reports"],
          "mappings": {"iso27001": ["10.1"], "soc2": ["CC7.3", "CC8.1"], "nist-csf": ["RS.MI-1", "RS.MI-2", "RC.IM-1"]}
        }
      ]
    },
    {
      "id": "A",
      "name": "Annex A — AI Risk Management Controls",
      "description": "Reference control objectives and controls specific to AI risk management, covering governance, impact assessment, lifecycle, data, bias, transparency, human oversight, and third-party AI",
      "controls": [
        {
          "id": "A.2",
          "title": "AI governance and accountability",
          "description": "The organization shall establish governance structures for AI including clear accountability mechanisms, ethical review boards, escalation procedures, and decision-making authority for AI-related matters.",
          "category": "AI Governance",
          "priority": 5,
          "typical_evidence": ["AI governance charter", "AI ethics review board terms of reference", "AI decision authority matrix", "AI accountability framework document", "Escalation procedure for AI decisions"],
          "mappings": {"iso27001": ["A6.1.1", "A5.1.1"], "soc2": ["CC1.2", "CC1.3"], "nist-csf": ["ID.GV-1", "ID.GV-2"]}
        },
        {
          "id": "A.3",
          "title": "AI impact assessment controls",
          "description": "The organization shall define criteria and processes for assessing the potential impact of AI systems on individuals, communities, and society, considering factors such as autonomy level, decision criticality, affected populations, and reversibility of outcomes.",
          "category": "AI Impact",
          "priority": 5,
          "typical_evidence": ["AI impact assessment criteria document", "Impact severity classification scheme", "Population impact analysis", "Autonomy level assessment", "Reversibility analysis for AI decisions"],
          "mappings": {"iso27001": ["A14.1.1"], "soc2": ["CC3.2", "CC9.2"], "nist-csf": ["ID.RA-1", "ID.RA-2", "ID.RA-4"]}
        },
        {
          "id": "A.4",
          "title": "AI system lifecycle controls",
          "description": "The organization shall implement controls throughout the AI system lifecycle including requirements specification, design, data acquisition, model training, validation, deployment, operation, monitoring, and retirement, with documented approval gates.",
          "category": "AI Lifecycle",
          "priority": 4,
          "typical_evidence": ["AI lifecycle process documentation", "Stage-gate approval records", "Model versioning records", "AI system retirement plan", "Lifecycle risk assessment at each stage"],
          "mappings": {"iso27001": ["A14.2.1", "A14.2.5"], "soc2": ["CC7.1", "CC8.1"], "nist-csf": ["PR.IP-1", "PR.IP-2", "PR.IP-3"]}
        },
        {
          "id": "A.5",
          "title": "Data quality and data management for AI",
          "description": "The organization shall establish controls for data quality assurance, data preprocessing, data labeling accuracy, data representativeness testing, data privacy protection, and data lifecycle management for AI training, testing, and inference data.",
          "category": "AI Data Quality",
          "priority": 5,
          "typical_evidence": ["Data quality policy for AI", "Data preprocessing pipeline documentation", "Data labeling quality assurance reports", "Data representativeness test results", "Data privacy impact assessments", "Training data documentation sheets"],
          "mappings": {"iso27001": ["A8.2.1", "A8.2.3", "A18.1.4"], "soc2": ["PI1.2", "PI1.3", "CC6.1"], "nist-csf": ["PR.DS-1", "PR.DS-6"]}
        },
        {
          "id": "A.6",
          "title": "Bias and fairness",
          "description": "The organization shall implement controls to identify, assess, mitigate, and monitor bias in AI systems, including demographic bias testing, fairness metric definition and tracking, disparate impact analysis, and remediation procedures for detected bias.",
          "category": "AI Fairness",
          "priority": 5,
          "typical_evidence": ["Bias assessment methodology", "Fairness metric definitions and thresholds", "Demographic bias testing reports", "Disparate impact analysis results", "Bias remediation action plans", "Ongoing bias monitoring dashboard"],
          "mappings": {"iso27001": ["A18.1.1"], "soc2": ["CC1.1", "PI1.2"], "nist-csf": ["ID.RA-1", "DE.CM-1"]}
        },
        {
          "id": "A.7",
          "title": "Transparency and explainability",
          "description": "The organization shall implement controls to ensure AI systems provide appropriate transparency and explainability, including documentation of model logic, provision of explanations to affected parties, and disclosure of AI involvement in decision-making.",
          "category": "AI Transparency",
          "priority": 5,
          "typical_evidence": ["AI transparency policy", "Model explainability reports", "AI disclosure notices to end users", "Model card documentation", "Explainability method selection rationale", "Public AI system register"],
          "mappings": {"iso27001": ["A18.1.1"], "soc2": ["CC2.1", "CC2.2"], "nist-csf": ["ID.GV-2", "PR.IP-1"]}
        },
        {
          "id": "A.8",
          "title": "Human oversight and control",
          "description": "The organization shall implement controls for human oversight of AI systems proportionate to the risk level, including human-in-the-loop mechanisms, override capabilities, escalation procedures, and defined thresholds for automated versus human decision-making.",
          "category": "AI Human Oversight",
          "priority": 5,
          "typical_evidence": ["Human oversight framework", "Human-in-the-loop procedure documentation", "Override mechanism specifications", "Automation boundary definitions", "Escalation threshold documentation", "Human review sampling plans"],
          "mappings": {"iso27001": ["A12.1.1", "A12.4.1"], "soc2": ["CC7.2", "CC7.3"], "nist-csf": ["DE.CM-1", "RS.RP-1"]}
        },
        {
          "id": "A.9",
          "title": "AI system security and robustness",
          "description": "The organization shall implement controls to ensure AI systems are secure and robust, addressing adversarial attacks, model poisoning, data integrity, model integrity, input validation, and resilience of AI systems under adverse conditions.",
          "category": "AI Security",
          "priority": 4,
          "typical_evidence": ["AI threat model documentation", "Adversarial robustness test results", "Model integrity verification records", "AI input validation procedures", "Model poisoning detection controls", "AI system resilience test reports"],
          "mappings": {"iso27001": ["A12.2.1", "A14.2.8"], "soc2": ["CC6.1", "CC7.2"], "nist-csf": ["PR.DS-1", "PR.DS-6", "PR.IP-2"]}
        },
        {
          "id": "A.10",
          "title": "Third-party AI components and services",
          "description": "The organization shall implement controls for managing risks associated with third-party AI components, including evaluation of pre-trained models, assessment of AI-as-a-Service providers, open-source AI component governance, and supply chain integrity for AI artifacts.",
          "category": "AI Supply Chain",
          "priority": 4,
          "typical_evidence": ["Third-party AI component register", "Pre-trained model evaluation reports", "AI vendor risk assessments", "Open-source AI governance policy", "AI supply chain integrity verification records", "Third-party AI SLA and contractual requirements"],
          "mappings": {"iso27001": ["A15.1.1", "A15.1.2", "A15.2.1"], "soc2": ["CC9.2"], "nist-csf": ["ID.SC-1", "ID.SC-2", "ID.SC-3", "ID.SC-4"]}
        }
      ]
    }
  ]
}
