#!/usr/bin/env python3
"""
PDF å’Œåœ–ç‰‡ OCR è™•ç†å·¥å…·ï¼ˆé€²éšç‰ˆï¼‰
ä½¿ç”¨ Ollama GLM-OCR æ¨¡å‹ï¼Œæ ¹æ“šå…§å®¹é¡å‹ï¼ˆæ–‡å­—/è¡¨æ ¼/åœ–è¡¨ï¼‰æ™ºèƒ½è½‰æ› PDF å’Œåœ–ç‰‡ç‚º Markdown
"""

import argparse
import sys
import os
from pathlib import Path
from typing import Optional

# å°‡ç•¶å‰ç›®éŒ„åŠ å…¥ Python è·¯å¾‘
SCRIPT_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPT_DIR))

from utils.ollama_client import OllamaClient
from utils.pdf_utils import pdf_to_images, get_pdf_page_count
from analyzer import PageAnalyzer, PageAnalysis, RegionType
from processor import RegionProcessor
from integrator import MarkdownIntegrator, assemble_markdown
from prompts import get_prompt


def check_environment(args) -> bool:
    """æª¢æŸ¥ç’°å¢ƒéœ€æ±‚ã€‚"""
    errors = []
    
    # æª¢æŸ¥ Ollama
    client = OllamaClient(host=args.host, port=args.port, model=args.model)
    ok, errs = client.check_status()
    if not ok:
        errors.extend(errs)
    
    # æª¢æŸ¥ pdftoppm
    if args.input.lower().endswith('.pdf'):
        try:
            import subprocess
            subprocess.run(["pdftoppm", "-h"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            errors.append("âš ï¸ pdftoppm æœªå®‰è£ï¼Œè«‹å®‰è£ poppler-utils ä»¥æ”¯æ´ PDF è™•ç†")
    
    if errors:
        print("ç’°å¢ƒæª¢æŸ¥è­¦å‘Šï¼š")
        for err in errors:
            print(f"  {err}")
        print("\nç¹¼çºŒåŸ·è¡Œå¯èƒ½å¤±æ•—...\n")
    
    return len(errors) == 0


def process_pdf(
    pdf_path: str,
    output_path: str,
    mode: str = "auto",
    granularity: str = "page",
    host: str = "localhost",
    port: str = "11434",
    model: str = "glm-ocr:q8_0",
    save_images: bool = False,
    custom_prompt: Optional[str] = None
) -> bool:
    """è™•ç† PDF æª”æ¡ˆã€‚"""
    print(f"ğŸ“„ è™•ç† PDF: {Path(pdf_path).name}")
    print(f"   æ¨¡å¼ï¼š{mode}")
    print(f"   ç²’åº¦ï¼š{granularity}")
    print(f"   æ¨¡å‹ï¼š{model}")
    
    # è½‰æ› PDF ç‚ºåœ–ç‰‡
    try:
        images = pdf_to_images(pdf_path, output_prefix=Path(pdf_path).stem + "_page")
        print(f"   è½‰æ›ç‚º {len(images)} å¼µåœ–ç‰‡")
    except Exception as e:
        print(f"âŒ PDF è½‰æ›å¤±æ•—ï¼š{e}")
        return False
    
    # åˆå§‹åŒ–çµ„ä»¶
    client = OllamaClient(host=host, port=port, model=model)
    analyzer = PageAnalyzer(ollama_client=client)
    processor = RegionProcessor(ollama_client=client, save_cropped_images=save_images)
    integrator = MarkdownIntegrator(save_images=save_images)
    
    # é€é è™•ç†
    analyses = []
    for i, img_path in enumerate(images, 1):
        page_num = Path(img_path).stem.split("_")[-1] if "_" in Path(img_path).stem else str(i)
        print(f"   ğŸ“ ç¬¬ {i}/{len(images)} é  ({page_num})...", end=" ")
        
        # åˆ†æé é¢
        auto_detect = (mode == "auto")
        analysis = analyzer.analyze_page(img_path, page_number=i, auto_detect=auto_detect)
        
        # è™•ç†å€åŸŸ
        processor.process_page_analysis(analysis)
        
        # ä¿å­˜çµæœ
        analyses.append(analysis)
        
        # æ¸…ç†è‡¨æ™‚åœ–ç‰‡
        try:
            os.remove(img_path)
        except:
            pass
        
        print("âœ…")
    
    # æ•´åˆè¼¸å‡º
    metadata = {
        "model": model,
        "mode": mode,
        "granularity": granularity,
        "source": Path(pdf_path).name
    }
    
    assemble_markdown(
        analyses,
        output_path,
        metadata=metadata,
        simple_mode=(granularity == "page")
    )
    
    print(f"\nâœ… å®Œæˆï¼çµæœå·²ä¿å­˜è‡³ï¼š{output_path}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°ï¼š{Path(output_path).stat().st_size / 1024:.1f} KB")
    
    return True


def process_image(
    image_path: str,
    output_path: str,
    mode: str = "mixed",
    host: str = "localhost",
    port: str = "11434",
    model: str = "glm-ocr:q8_0",
    custom_prompt: Optional[str] = None
) -> bool:
    """è™•ç†å–®ä¸€åœ–ç‰‡ã€‚"""
    print(f"ğŸ–¼ï¸ è™•ç†åœ–ç‰‡ï¼š{Path(image_path).name}")
    print(f"   æ¨¡å¼ï¼š{mode}")
    print(f"   æ¨¡å‹ï¼š{model}")
    
    # åˆå§‹åŒ–çµ„ä»¶
    client = OllamaClient(host=host, port=port, model=model)
    analyzer = PageAnalyzer(ollama_client=client)
    processor = RegionProcessor(ollama_client=client)
    integrator = MarkdownIntegrator(save_images=False)
    
    # åˆ†æé é¢
    auto_detect = (mode == "auto")
    analysis = analyzer.analyze_page(image_path, page_number=1, auto_detect=auto_detect)
    
    # è™•ç†å€åŸŸ
    processor.process_page_analysis(analysis)
    
    # æ•´åˆè¼¸å‡º
    metadata = {
        "model": model,
        "mode": mode,
        "source": Path(image_path).name
    }
    
    assemble_markdown(
        [analysis],
        output_path,
        metadata=metadata,
        simple_mode=True
    )
    
    print(f"âœ… å®Œæˆï¼çµæœå·²ä¿å­˜è‡³ï¼š{output_path}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°ï¼š{Path(output_path).stat().st_size / 1024:.1f} KB")
    
    return True


def main():
    """ä¸»å‡½æ•¸ã€‚"""
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Ollama GLM-OCR å°‡ PDF æˆ–åœ–ç‰‡è½‰æ›ç‚º Markdownï¼ˆæ™ºèƒ½åˆ†é¡è™•ç†ï¼‰"
    )
    
    # å¿…è¦åƒæ•¸
    parser.add_argument("--input", "-i", required=True, help="è¼¸å…¥æª”æ¡ˆè·¯å¾‘ (PDF æˆ–åœ–ç‰‡)")
    parser.add_argument("--output", "-o", required=True, help="è¼¸å‡º Markdown æª”æ¡ˆè·¯å¾‘")
    
    # æ¨¡å¼é¸æ“‡
    parser.add_argument(
        "--mode", "-m",
        choices=["text", "table", "figure", "mixed", "auto"],
        default="auto",
        help="è­˜åˆ¥æ¨¡å¼ï¼štext(ç´”æ–‡å­—)/table(è¡¨æ ¼)/figure(åœ–è¡¨)/mixed(æ··åˆ)/auto(è‡ªå‹•æª¢æ¸¬)"
    )
    
    # è™•ç†ç²’åº¦
    parser.add_argument(
        "--granularity", "-g",
        choices=["page", "region", "block"],
        default="page",
        help="è™•ç†ç²’åº¦ï¼špage(æ•´é )/region(å€åŸŸ)/block(å€å¡Š)"
    )
    
    # æ¨¡å‹é…ç½®
    parser.add_argument(
        "--model",
        default="glm-ocr:q8_0",
        help=f"ä½¿ç”¨çš„æ¨¡å‹ (é è¨­ï¼šglm-ocr:q8_0)"
    )
    parser.add_argument(
        "--host",
        default="localhost",
        help=f"Ollama ä¸»æ©Ÿä½ç½® (é è¨­ï¼šlocalhost)"
    )
    parser.add_argument(
        "--port",
        default="11434",
        help=f"Ollama ç«¯å£ (é è¨­ï¼š11434)"
    )
    
    # å…¶ä»–é¸é …
    parser.add_argument(
        "--prompt", "-p",
        help="è‡ªè¨‚æç¤ºè©ï¼ˆæœƒè¦†è“‹é è¨­æç¤ºè©ï¼‰"
    )
    parser.add_argument(
        "--check", "-c",
        action="store_true",
        help="åƒ…æª¢æŸ¥ç’°å¢ƒéœ€æ±‚"
    )
    parser.add_argument(
        "--save-images",
        action="store_true",
        help="ä¿å­˜åœ–è¡¨å€åŸŸçš„åœ–ç‰‡"
    )
    
    args = parser.parse_args()
    
    # æª¢æŸ¥ç’°å¢ƒ
    if args.check:
        check_environment(args)
        sys.exit(0)
    
    check_environment(args)
    
    # è™•ç†æª”æ¡ˆ
    input_path = Path(args.input)
    
    if not input_path.exists():
        print(f"âŒ è¼¸å…¥æª”æ¡ˆä¸å­˜åœ¨ï¼š{input_path}")
        sys.exit(1)
    
    if input_path.suffix.lower() in [".pdf"]:
        success = process_pdf(
            str(input_path),
            args.output,
            mode=args.mode,
            granularity=args.granularity,
            host=args.host,
            port=args.port,
            model=args.model,
            save_images=args.save_images,
            custom_prompt=args.prompt
        )
    elif input_path.suffix.lower() in [".png", ".jpg", ".jpeg", ".webp", ".gif"]:
        success = process_image(
            str(input_path),
            args.output,
            mode=args.mode,
            host=args.host,
            port=args.port,
            model=args.model,
            custom_prompt=args.prompt
        )
    else:
        print(f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼š{input_path.suffix}")
        print("æ”¯æ´çš„æ ¼å¼ï¼šPDF, PNG, JPG, JPEG, WEBP, GIF")
        sys.exit(1)
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
